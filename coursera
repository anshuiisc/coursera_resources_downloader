#! /usr/bin/env python
from __future__ import print_function
from multiprocessing import Pool
from lxml import etree
import requests
from requests.exceptions import RequestException
import argparse
import platform
import getpass
import string
import sys
import os
import re

RESOURCE_DICTS_BY_I_CLASS = {'icon-file': {'arg': 'pdfs',  'extension': 'pdf'},
                             'icon-picture': {'arg': 'pptx',  'extension': 'pptx'},
                             'icon-align-justify': {'arg': 'txt',  'extension': 'txt'},
                             'icon-list': {'arg': 'subs',  'extension': 'srt'},
                             'icon-download-alt': {'arg': 'video', 'extension': 'mp4'}}

WIN_VALID_CHARS = '-_.() ' + string.ascii_letters + string.digits
MAX_WIN_FILE_SIZE = 50
MAX_LINUX_FILE_SIZE = 140
IS_WINDOWS = platform.system() == 'Windows'


def make_valid_filename(filename):
    if IS_WINDOWS:
        return ''.join((c if c in WIN_VALID_CHARS else '_') for c in filename)[:MAX_WIN_FILE_SIZE]
    else:
        return filename.replace(os.sep, '_')[:MAX_LINUX_FILE_SIZE]


# Based in PabloG answer at http://stackoverflow.com/questions/22676/how-do-i-download-a-file-over-http-using-python
def download_to_file(raw_resp, file_name):
    try:
        with open(file_name, 'wb') as f:
            length_header = raw_resp.getheader('content-length')
            file_size = int(length_header) if length_header else None
            print('Downloading: {0}'.format(file_name))

            file_size_dl = 0
            block_sz = 8192
            while True:
                buf = raw_resp.read(block_sz)
                if not buf:
                    break

                file_size_dl += len(buf)
                f.write(buf)
                fsdmb = '{0:d}'.format(file_size_dl / 1000000)
                fsdkb = '{0:03d}'.format(file_size_dl / 1000 % 1000)
                fsd = '{0}.{1}'.format(fsdmb, fsdkb)
                if file_size:
                    fsmb = '{0:d}'.format(file_size / 1000000)
                    fskb = '{0:03d}'.format(file_size / 1000 % 1000)
                    fs = '{0}.{1}'.format(fsmb, fskb)
                    percentage = '{0:.2f}'.format(file_size_dl * 100. / file_size)
                    status = r'{0:>8s}/{1:s} Mb [{2}%]'.format(fsd, fs, percentage)
                else:
                    status = r'{0:>8s} Mb'.format(fsd)
                status = status + chr(8) * (len(status) + 1)
                print(status, end='')
    except KeyboardInterrupt:
        print('\nDownload was interrupted. Removed partially downloaded file.')
        os.remove(file_name)
        sys.exit()
    except Exception:
        os.remove(file_name)
        raise


def clean_lecture_name(lecture_name):
    if '(' in lecture_name:
        lecture_name = lecture_name.rpartition('(')[0]
    return lecture_name.strip()


WEEK_RE = re.compile(r'(.*)\(week (\d+)\)$')
def take_week_from_section(section):
    week = 0
    match = WEEK_RE.match(section)
    if match:
        section, week = match.groups()
        section = section.strip()
        week = int(week)
    return section, week


def compare_sections(s1, s2):
    if (s1[1] != s2[1]):
        return s1[1] - s2[1]
    if (s1[2] != s2[2]):
        return s1[1] - s2[1]
    assert False


DATA_FORMAT = 'define\(\["js/collections/courses"\],function\(a\)\{return new a\((.*)\)\}\)'
COURSES_RE = '\{id:\d+,.*?,title:"(.+?)",.*?,short_name:"(.+?)",.*?,status:(\d+)}'
def list_course_ids(args):
    home_page_url = 'https://www.coursera.org/static/min/445280c31f89061672d5b00b72f0de755ce57eab/js/data/courses.js'
    try:
        doc = requests.get(home_page_url).text
    except RequestException:
        print('ERROR: Failed to open home page for reasons unknown')
        return
    match = re.match(DATA_FORMAT, doc)
    if match:
        courses = match.groups()[0]
        data = re.findall(COURSES_RE, courses)
        ids = []
        for title, short_name, status in data:
            if int(status) in (1,2):
                ids.append('{0} -> {1}'.format(short_name, title))
        print('\n'.join(sorted(ids)))


def download_resources(args):
    if not args.dl_all and not any(getattr(args, res_dict['arg']) for res_dict in RESOURCE_DICTS_BY_I_CLASS.values()):
        print('ERROR: You disabled video download but didn\'t enable any other resource for download.')
        return

    if not args.password:
        args.password = getpass.getpass('Coursera password: ')

    print('Authenticating')
    data = {'email_address':args.email, 'password': args.password}
    maestro_resp = requests.post('https://www.coursera.org/maestro/auth/api/user/login', data=data)
    if maestro_resp.status_code == 401:
        print('ERROR: Authentication failed, please check your email and password.')
        return
    print('Authentication successful')
    for course_id in filter(None, args.course_ids.split(',')):
        print()
        download_course_resources(args, maestro_resp.cookies, course_id)


def download_course_resources(args, maestro_cookies, course_id):
    print('Trying to open lecture index page for the {0} course'.format(course_id))
    course_url = 'https://class.coursera.org/{0}/lecture/index'.format(course_id)
    try:
        course_resp = requests.get('https://class.coursera.org/{0}/auth/auth_redirector?type=login&subtype=normal'.format(course_id), cookies=maestro_cookies)
        lecture_resp = requests.get('https://class.coursera.org/{0}/lecture/index'.format(course_id), cookies=course_resp.cookies)
    except RequestException as err:
        print('ERROR: Failed to open lecture index page at {0}'.format(course_url))
        print('This is probably a bug, so please report it on github and provide the following two lines:')
        print('Err: {0}'.format(str(err)))
        return

    print('Done')
    tree = etree.HTML(lecture_resp.text)
    course_title_element = tree.xpath('//div[@id="course-logo-text"]/a/img/@alt')
    if not course_title_element:
        print('ERROR: Failed to open lecture index page at {0}'.format(course_url))
        print('Please make sure that you are enrolled in the {0} course and that it has already started.'.format(course_id))
        return
    course_title = course_title_element[0].strip()
    course_title = make_valid_filename(course_title)

    item_list = tree.xpath('//div[@class="item_list"]')[0]
    print('Starting downloads')
    sections = []
    for i in xrange(0, len(item_list)/2):
        section_el, lecture_list_el = item_list[2*i], item_list[2*i+1]
        section = section_el.xpath('./h3/text()')[0].strip()
        no_week_section, week = take_week_from_section(section)
        sections.append((no_week_section, week, i, lecture_list_el))
    sections = sorted(sections, compare_sections)

    for i, (no_week_section, week, _, lecture_list_el) in enumerate(sections, 1):
        section = '{0} - {1}'.format(i, no_week_section)
        if week:
            section += ' (week {0})'.format(week)
        section = make_valid_filename(section)
        section_folder = os.path.join(course_title, section)
        if not os.path.exists(section_folder):
            os.makedirs(section_folder)
        lecture_names = [name for name in lecture_list_el.xpath('./li/a/text()') if name.strip()]
        final_lecture_names = []
        for j, lecture_name in enumerate(lecture_names, 1):
            lecture_name = clean_lecture_name(lecture_name)
            lecture_name = '{0} - {1}'.format(j, lecture_name)
            if args.section_lecture_format:
                lecture_name = '{0}.{1}'.format(i, lecture_name)
            lecture_name = make_valid_filename(lecture_name)
            lecture_name = os.path.join(section_folder, lecture_name)
            final_lecture_names.append(lecture_name)
        lecture_div_list = lecture_list_el.xpath('./li/div[@class="item_resource"]')
        for final_lecture_name, lecture_div in zip(final_lecture_names, lecture_div_list):
            url_list = lecture_div.xpath('./a/@href')
            resource_icon_class_list = [classes.split(' ')[0] for classes in lecture_div.xpath('./a/i/@class')]
            for resource_img, resource_dict in RESOURCE_DICTS_BY_I_CLASS.items():
                if args.dl_all or getattr(args, resource_dict['arg']):
                    filetype_urls = [url for url, img in zip(url_list, resource_icon_class_list) if img == resource_img]
                    add_ft_counter = len(filetype_urls) > 1
                    for j, filetype_url in enumerate(filetype_urls, 1):
                        ft_counter = '{0}.'.format(j) if add_ft_counter else ''
                        full_file_name = '{0}.{1}{2}'.format(final_lecture_name, ft_counter, resource_dict['extension'])
                        if not os.path.exists(full_file_name):
                            try:
                                raw_resp = requests.get(filetype_url, cookies=course_resp.cookies).raw
                                download_to_file(raw_resp, full_file_name)
                            except Exception as err:
                                print('ERROR: Could not download the following resource: {0}'.format(filetype_url))
                                print('Please check if you can download the resource manually.')
                                print('If you can then this is a bug, so please report it on github and provide the following two lines:')
                                print('URL: {0}'.format(filetype_url))
                                print('Err: {0}'.format(str(err)))

    print('All requested resources for the {0} course have been downloaded'.format(course_id))


def main():
    parser = argparse.ArgumentParser(description='Automatize tasks in Coursera course\'s sites. (Downloading resources is pretty much all it can do now but more functionalities might get added latter)')
    subparsers = parser.add_subparsers(help='Available subcommands.')
    dl_res_parser = subparsers.add_parser('dl_res', help='Gets lecture resources (videos by default) of an online Coursera course.')
    dl_res_parser.add_argument('course_ids', help='Course identifiers separated by commas. Run the script once with the subcommand list-course-ids to see the ones available.')
    dl_res_parser.add_argument('email', help='Your coursera email.')
    dl_res_parser.add_argument('password', nargs='?', default=None, help='Your coursera password. You can omit it in the command line and provide it interactively.')
    dl_res_parser.add_argument('--all', dest='dl_all', action='store_true', help='Downloads all available resources (video, pdfs, pptx, etc.). Disabled by default.')
    dl_res_parser.add_argument('--pdfs', action='store_true', help='Get the pdfs for each lecture. Disabled by default.')
    dl_res_parser.add_argument('--pptx', action='store_true', help='Get the pptx\'s for each lecture. Disabled by default.')
    dl_res_parser.add_argument('--txt', action='store_true', help='Get the text subtitles for each lecture. Disabled by default.')
    dl_res_parser.add_argument('--subs', action='store_true', help='Get the srt subtitles for each lecture. Disabled by default.')
    dl_res_parser.add_argument('--no-video', dest='video', action='store_false', help='Do not download the videos. Use this if you only want other resources such as pdfs.')
    dl_res_parser.add_argument('--section-lecture-format', dest='section_lecture_format', action='store_true', help='Use the section number on the name of lectures. Ex: file abc which belongs to the first lecture of section 2 will get named 2.1 - abc.')
    dl_res_parser.set_defaults(func=download_resources)

    lst_ids_parser = subparsers.add_parser('list-course-ids', help='Use this option to get a list of the available course ids.')
    lst_ids_parser.set_defaults(func=list_course_ids)

    args = parser.parse_args()
    args.func(args)


if __name__ == '__main__':
    main()
